{
  "hash": "5bcdf5dcb1ba331712a4c026defd7528",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Sistema Inteligente Integrado para Predicción, Clasificación y Recomendación en la Empresa de Transporte\"\nauthor:\n  - name: \"Alejandro Feria González, aferiag@unal.edu.co\"\n  - name: \"Andres Felipe Arismendi Alzate, aarismendi@unal.edu.co\"\n  - name: \"Abraham David Miguel Cardenas, amiguel@unal.edu.co\"\n  - name: \"Santiago Molina Munoz, smolinam@unal.edu.co\"\ndate: \"2025-06-30\"\ncategories: [Redes Neuronales, Algoritmos bioinspirados]\nimage: \"image.png\"\nformat:\n  html:\n    number-sections: true\n    code-fold: true\n    toc: true\n    toc-title: \"Tabla de contenido\"\n    toc-location: left-body\n    css: custom.css\npage-layout: full\nexecute:\n  cache: true\njupyter: python3\n---\n\n# Resumen Ejecutivo\nEste reporte detalla el desarrollo de un sistema inteligente basado en aprendizaje profundo, diseñado para abordar tres desafíos críticos en una empresa de transporte: la optimización de recursos mediante la predicción de demanda, la mejora de la seguridad vial a través de la clasificación de comportamientos distractivos en conductores, y la personalización de la experiencia del usuario con un sistema de recomendación de destinos.\n\nEl proyecto se centró en la creación de tres módulos: un modelo de series de tiempo para predecir la demanda de transporte con 30 días de antelación, un clasificador de imágenes para identificar conductas distractivas como el uso del teléfono móvil, y un sistema de recomendación que sugiere destinos personalizados a los usuarios basándose en su historial y preferencias. Todas estas soluciones se integraron en una herramienta web intuitiva creada con FastAPI. Para la realizacion de los modelos se uso tensorflow y keras, ademas de Sklearn.\n\nLos resultados preliminares demuestran la viabilidad y el potencial impacto del sistema. El modelo de predicción de demanda alcanzó un RMSE de [Valor de RMSE] y un MAE de [Valor de MAE], lo que permite una planificación más precisa de la asignación de vehículos y personal. El clasificador de conducción distractiva logró una precisión del [Porcentaje de Precisión]% en la detección de comportamientos de riesgo, contribuyendo significativamente a la seguridad. Finalmente, el sistema de recomendación generó recomendaciones pertinentes, con una Precision de [Valor de Precision] y Recall de [Valor de Recall].\n\nEn conclusión, este sistema inteligente representa un avance significativo en la eficiencia operativa, la seguridad vial y la experiencia del cliente para la empresa de transporte, sentando las bases para futuras optimizaciones y expansiones.\n\n# Introducción\nLa industria del transporte se encuentra en una constante evolución, enfrentando desafíos como la fluctuación impredecible de la demanda, la imperante necesidad de garantizar la seguridad vial y la creciente expectativa de los usuarios por servicios personalizados. En este contexto, las empresas buscan soluciones innovadoras que les permitan optimizar sus operaciones, mitigar riesgos, maximizar ganancias y fidelizar a sus clientes. El aprendizaje profundo (Deep Learning) emerge como una tecnología clave, capaz de procesar grandes volúmenes de datos complejos para extraer patrones y tomar decisiones inteligentes, que manualmente serían inviables.\n\nEl presente proyecto aborda estas problemáticas mediante el desarrollo de tres modulos para predicción, clasificación y recomendación.\n\n## Objetivo General\nDesarrollar un sistema inteligente basado en aprendizaje profundo que integre la predicción de la demanda de transporte, la clasificación de comportamientos distractores de los conductores mediante imágenes, y un sistema de recomendaciones personalizadas para mejorar la eficiencia y seguridad de los servicios de transporte.\n\n## Objetivos Específicos\n* Entrenar un modelo de series de tiempo utilizando los datos históricos de la empresa para predecir la demanda de transporte en rutas específicas durante los próximos 30 días.\n* Implementar un modelo de clasificación de imágenes para identificar comportamientos distractores de los conductores, como el uso de teléfonos móviles o somnolencia.\n* Desarrollar un sistema de recomendaciones personalizadas para sugerir destinos de viaje en función del historial de viajes y las preferencias de los usuarios de la empresa.\n* Construir una herramienta web que integre todas las soluciones desarrolladas, permitiendo visualizar los resultados y probar los modelos de predicción, clasificación y recomendación.\n* Documentar el proceso de desarrollo en un informe técnico detallado y profesional.\n\n## Alcances\nEl proyecto abarca el diseño, desarrollo y evaluación de tres módulos principales de aprendizaje profundo: predicción de demanda (con un horizonte de 30 días), clasificación de imágenes de conducción distractiva (identificando comportamientos específicos) y un sistema de recomendación de destinos. La integración de estos módulos se realizará a través de una aplicación web funcional que permitirá la interacción con los modelos y la visualización de sus resultados.\n\n## Limitaciones\nLas limitaciones del proyecto incluyen la disponibilidad y calidad de los datos históricos, que pueden influir en la precisión de las predicciones y clasificaciones. Los recursos computacionales y el tiempo de desarrollo son factores restrictivos que pueden limitar la complejidad de los modelos o la exhaustividad de las pruebas. La generalización de los modelos a escenarios o comportamientos no vistos en los datos de entrenamiento también representa un desafío inherente al aprendizaje automático.\n\nPara el despliegue de la herramienta web, debido a que se un proyecto académico, los recursos en la nube pueden ser limitados, lo que podría afectar la escalabilidad y disponibilidad del sistema. Además, la implementación de medidas de seguridad y privacidad de los datos de los usuarios es crucial, pero puede ser compleja y requerir consideraciones adicionales.\n\n# Metodología\nLa metodología adoptada para el desarrollo de este sistema inteligente se basa en un enfoque modular y iterativo, siguiendo las mejores prácticas en el campo del aprendizaje automático y la ingeniería de software. Se usa git para el control de versiones y la colaboración en el desarrollo del código. Se usa CI/CD para asegurar la calidad del código y la integración continua de los módulos desarrollados.\n\n## Explicación de Conceptos Clave\n\n* Aprendizaje Profundo (Deep Learning): Una rama del aprendizaje automático que utiliza redes neuronales artificiales con múltiples capas (profundas) para modelar abstracciones de alto nivel en los datos. Fue elegido por su capacidad para manejar grandes volúmenes de datos complejos (series de tiempo, imágenes, interacciones de usuario) y extraer características automáticamente, lo que es crucial para la complejidad de los problemas planteados.\n\n* Series de Tiempo: Secuencias de puntos de datos indexados (o listados) en orden de tiempo. La predicción de series de tiempo implica el uso de modelos para pronosticar valores futuros basándose en patrones históricos, estacionalidad y tendencias.\n\n* Redes Neuronales Convolucionales (CNNs): Un tipo de red neuronal profunda especialmente diseñada para procesar datos con una topología de cuadrícula, como imágenes. Las CNNs son ideales para la clasificación de imágenes de conducción distractiva debido a su capacidad para aprender jerarquías de características espaciales.\n\n* Sistemas de Recomendación: Algoritmos que sugieren elementos (destinos de viaje en este caso) a los usuarios basándose en sus preferencias pasadas y/o en el comportamiento de usuarios similares. Pueden ser basados en filtrado colaborativo (utilizando similitudes entre usuarios o ítems), basados en contenido (utilizando atributos de los ítems) o híbridos.\n\n## Enfoque General del Proyecto\nEl proyecto se estructuró en torno a un enfoque modular, donde cada uno de los tres problemas principales (predicción de demanda, clasificación de conducción distractiva y recomendación de destinos) fue abordado como un módulo independiente con su propio ciclo de vida de desarrollo de modelo. Posteriormente, estos módulos se integraron en una única plataforma web para ofrecer una solución unificada. Este enfoque permitió la especialización en cada área y facilitó la gestión de la complejidad del proyecto.\n\n## Fases del Proyecto\nFase 1: Recopilación y Exploración de Datos:\n\n  * Identificación y acceso a las fuentes de datos para cada módulo (registros de transporte, imágenes de conductores, historial de viajes de usuarios).\n\n  * Análisis Exploratorio de Datos (EDA) para comprender la estructura, calidad y patrones iniciales de los datos. Visualización de tendencias, distribución y anomalías.\n\nFase 2: Preprocesamiento de Datos:\n\n  * Limpieza de Datos: Manejo de valores nulos, duplicados y atípicos.\n\n  * Transformación: Normalización, estandarización, creación de características (feature engineering) específicas para cada tipo de dato (ej. características temporales para series de tiempo, aumento de datos para imágenes).\n\n  * División de Datos: Separación en conjuntos de entrenamiento, validación y prueba para asegurar una evaluación imparcial del modelo.\n\nFase 3: Desarrollo y Entrenamiento de Modelos:\n\n  * Diseño de Arquitecturas: Selección y diseño de las arquitecturas de redes neuronales profundas más adecuadas para cada módulo (ej. LSTMs para series de tiempo, CNNs para imágenes, modelos de factorización de matrices o redes neuronales para recomendaciones).\n\n  * Implementación: Codificación de los modelos utilizando las librerías de aprendizaje profundo seleccionadas.\n\n  * Entrenamiento: Proceso de ajuste de los pesos de los modelos utilizando los datos de entrenamiento, con monitoreo del rendimiento en el conjunto de validación.\n\nFase 4: Evaluación y Optimización:\n\n  * Definición de Métricas: Selección de métricas de rendimiento apropiadas para cada tipo de problema (RMSE, MAE para predicción; Accuracy, F1-score, Precision, Recall para clasificación; Precision, Recall para recomendación).\n\n  * Evaluación: Medición del rendimiento de los modelos en el conjunto de prueba, no visto durante el entrenamiento.\n\n  * Optimización: Ajuste de hiperparámetros y refinamiento de las arquitecturas para mejorar el rendimiento.\n\nFase 5: Integración y Desarrollo Web:\n\n  * Diseño de la Arquitectura Web: Planificación de la estructura de la aplicación web, incluyendo frontend, backend y la comunicación con los modelos.\n\n  * Desarrollo de APIs: Creación de interfaces de programación de aplicaciones (APIs) para que la aplicación web pueda interactuar con los modelos entrenados.\n\n  * Implementación de la Interfaz de Usuario: Desarrollo del frontend para visualizar resultados y permitir la interacción del usuario.\n\nFase 6: Pruebas y Despliegue:\n\n    Pruebas de Funcionalidad: Verificación de que todas las características del sistema integrado funcionan según lo esperado.\n\n    Pruebas de Rendimiento: Evaluación de la velocidad y eficiencia del sistema.\n\n    Despliegue: Preparación y lanzamiento del sistema en un entorno de producción. Se uso [Render](https://render.com/) para el despliegue de la aplicación web, permitiendo que los usuarios accedan a la herramienta desde cualquier lugar.\n\n## Herramientas y Tecnologías Utilizadas\n* Lenguaje de Programación: Python\n* Librerías de Aprendizaje Profundo: TensorFlow, Keras, Scikit-learn\n* Librerías de Manipulación de Datos: Pandas, NumPy\n* Librerías de Visualización: Matplotlib\n* Desarrollo Web (Backend): FastAPI\n* Desarrollo Web (Frontend): Javascript vanilla para la interactividad y Tailwind CSS para los estilos de la página web.\n* Entorno de Desarrollo: Jupyter Notebooks, VS Code\n* Control de Versiones: Git, GitHub\n\n# Desarrollo Técnico por Módulo\n\n## Módulo 1: Predicción de Demanda de Transporte\n### Descripción del Problema\nEl primer reto consiste en anticipar la demanda de transporte en rutas específicas durante los próximos 30 días. Esta predicción es esencial para garantizar que la empresa cuente con los recursos adecuados —vehículos, conductores y personal de apoyo— en los momentos y lugares donde se necesiten.\n\nPara ello, se entrenará un modelo de series de tiempo sobre un conjunto de datos históricos reales proporcionado por el CRTM, el cual contiene información detallada de validaciones de transporte público (como número de pasajeros transportados por ruta y por fecha). Este módulo no solo busca predecir la evolución temporal de la demanda, sino también generar información útil para optimizar la planificación operativa, reducir tiempos de espera, minimizar recursos ociosos y mejorar la calidad del servicio.\n\nLa solución propuesta se fundamenta en técnicas de aprendizaje profundo especializadas en series temporales, tales como redes neuronales recurrentes (RNN), LSTM o modelos más modernos como Temporal Fusion Transformers. El objetivo es capturar patrones de estacionalidad, tendencias y variaciones anómalas que caracterizan el comportamiento de la demanda de transporte urbano en una ciudad como Madrid.\n\nEl conjunto de datos utilizado proviene del portal de datos abiertos del Consorcio Regional de Transportes de Madrid (CRTM). Este dataset, aunque sencillo en estructura, contiene información esencial para el análisis: fecha, modo de transporte (por ejemplo, autobús, metro o cercanías) y número de pasajeros transportados. A partir de estas variables, es posible construir una serie temporal robusta para cada modo de transporte, capturando patrones diarios, estacionales y tendencias a lo largo del tiempo. Esta base, al representar datos reales de demanda, resulta adecuada para entrenar modelos de predicción orientados a mejorar la planificación operativa.\n\n::: {#d1f71b6a .cell execution_count=2}\n``` {.python .cell-code}\nimport pandas as pd\n# https://datos.crtm.es/documents/a7210254c4514a19a51b1617cfd61f75/about\nruta_al_archivo = './transporte_madrid.csv'\ndf = pd.read_csv(ruta_al_archivo)\ndf['Fecha'] = pd.to_datetime(df['Fecha'], dayfirst=True)\n# 4. Crear columna `Month` como pide prepare_data\ndf.rename(columns={'Fecha': 'Month', 'Valor': '#Passengers'}, inplace=True)\ndf = df.groupby('Month')['#Passengers'].sum().reset_index()\n```\n:::\n\n\n### Dataset\n\n#### Descripción del Conjunto de Datos\n\nPara el desarrollo del modelo de predicción de demanda de transporte, se utilizó un conjunto de datos abierto proporcionado por el Consorcio Regional de Transportes de Madrid (CRTM). Este conjunto contiene información agregada sobre el uso del sistema de transporte público por día y modo de transporte, permitiendo construir series temporales por categoría.\n\n#### Estructura del conjunto de datos\n\nEl archivo contiene tres variables principales:\n\n| Variable | Descripción                                              | Tipo       |\n| -------- | -------------------------------------------------------- | ---------- |\n| `Fecha`  | Fecha de la observación (formato AAAA-MM-DD)             | Fecha      |\n| `Modo`   | Tipo de transporte utilizado (Ej: METRO, BUS, CERCANÍAS) | Categórica |\n| `Valor`  | Número de pasajeros registrados en esa fecha      | Numérica   |\n\n\n#### Dimensiones del conjunto\n* Cobertura temporal: Desde el 1 de enero de 2023 hasta el 29 de junio de 2025 (2.5 años).\n* Total de registros: 911 observaciones (dependiendo del número de modos y días disponibles).\n\n#### Ejemplo de registros\n\n| Fecha      | Modo      | Valor     |\n| ---------- | --------- | --------- |\n| 2023-02-15 | BUS       | 945.218   |\n| 2023-02-15 | METRO     | 1.221.504 |\n| 2023-02-15 | CERCANÍAS | 287.564   |\n\n\n#### Consideraciones para el modelado\n* Los datos están agregados a nivel diario por modo, sin segmentación por línea, estación o franja horaria.\n\n* No se cuenta con variables exógenas (clima, festivos, eventos), por lo que el enfoque será univariado por serie, aunque se puede modelar cada modo de transporte por separado o con modelos multivariados si se decide combinar las series.\n\n* Se observan patrones de estacionalidad semanal y anual, así como efectos de calendario (como menor demanda en fines de semana o festivos).\n\n::: {#a390608c .cell execution_count=3}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\n# Ordenar y tomar los últimos 30 días\ndf_last_30 = df.sort_values('Month').tail(90)\n\n# Graficar la serie temporal\nplt.figure(figsize=(12, 5))\nplt.plot(df_last_30['Month'], df_last_30['#Passengers'], marker='o')\nplt.title(f'Demanda diaria de los últimos 90 días')\nplt.xlabel('Fecha')\nplt.ylabel('Número de pasajeros')\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-3-output-1.png){}\n:::\n:::\n\n\n### Preprocesamiento\n\n#### Preparación y Visualización de los Datos\nAntes de entrenar cualquier modelo de predicción, es fundamental realizar una limpieza, transformación y exploración inicial de los datos. Esto permite detectar patrones relevantes, anomalías y estacionalidades que influyen directamente en la demanda de transporte.\n\n1. Carga y limpieza inicial\n  * Se importó el conjunto de datos desde un archivo .csv con codificación UTF-8.\n  * Se estandarizó el tipo de dato Fecha y se verificó la ausencia de valores nulos.\n  * Se eliminaron registros con valores de pasajeros iguales a cero o inconsistencias por duplicación.\n\n2. Agregación por modo de transporte: Aunque los datos están segmentados por modo (BUS, METRO, CERCANÍAS), se decidió trabajar inicialmente con series separadas para cada uno, dada la naturaleza operativa distinta de cada sistema.\n\n3. Visualización exploratoria\nSe graficó la demanda diaria de cada modo de transporte, lo que permitió identificar varios patrones:\n\n  * Tendencia general: Incremento progresivo de la demanda.\n  * Estacionalidad semanal: Caídas evidentes los fines de semana, especialmente domingos.\n  * Estacionalidad anual: Reducción de demanda en los meses de verano y festivos largos.\n  * Picos y valles anómalos: Algunos días con valores atípicos por eventos excepcionales o errores de medición.\n\n4. Transformaciones aplicadas\n  * Se aplicó una transformación logarítmica opcional para estabilizar la varianza (en caso de que el modelo lo requiera).\n * Se realizaron pruebas de estacionariedad (Dickey-Fuller) para evaluar la necesidad de diferenciar la serie.\n\n#### Preparación de datos y creación de secuencias\nSe diseñó una clase personalizada TimeSeriesDataset compatible con torch.utils.data.Dataset, encargada de generar automáticamente las secuencias de entrada (X) y las etiquetas de salida (y) necesarias para el entrenamiento del modelo. Cada muestra consiste en una secuencia de longitud fija (sequence_length) y su correspondiente valor siguiente como objetivo de predicción.\n\nEl código realiza lo siguiente:\n\n  * Convierte la serie escalada a FloatTensor.\n  * Divide la serie en múltiples pares (secuencia, objetivo), usando una ventana deslizante.\n  * Cada secuencia se entrega como un tensor de tamaño (sequence_length, 1).\n\n#### División temporal del conjunto de datos\nSe utilizó una estrategia de validación temporal para dividir el conjunto de datos en entrenamiento y validación:\n\n* Los datos anteriores al 1 de marzo de 2025 se usan para entrenamiento.\n* Los datos desde esa fecha se utilizan para validar la capacidad de generalización del modelo.\n\nEsta división respeta la naturaleza temporal de la serie y evita fugas de información del futuro hacia el pasado.\n\n#### Escalamiento\nDado que las redes neuronales son sensibles a la escala de los datos, se aplicó una transformación MinMaxScaler() a los valores de pasajeros. Esta transformación se ajusta con los datos de entrenamiento y luego se aplica a los de validación.\n\n#### Carga eficiente con DataLoader\nLos datos se organizan y cargan mediante DataLoader, que permite:\n\n  * Entrenamiento en mini-lotes (batch_size=16) para mejorar la estabilidad del gradiente y la eficiencia computacional.\n  * Mezcla aleatoria de las secuencias de entrenamiento (shuffle=True).\n  * Validación con todos los datos de validación disponibles como un único lote.\n\n\n#### Codigo para la preparación de datos\n\n```python\nclass TimeSeriesDataset(Dataset):\n    \"\"\"\n    Custom Dataset class for time series data.\n\n    This class handles the creation of sequences and targets for time series prediction,\n    implementing the necessary methods for PyTorch's Dataset class.\n    \"\"\"\n    def __init__(self, data, sequence_length):\n        \"\"\"\n        Initialize the dataset.\n\n        Parameters:\n        data (numpy.array): Input time series data\n        sequence_length (int): Length of input sequences\n        \"\"\"\n        self.data = torch.FloatTensor(data)\n        self.sequence_length = sequence_length\n\n    def __len__(self):\n        \"\"\"Return the number of sequences in our dataset.\"\"\"\n        return len(self.data) - self.sequence_length\n\n    def __getitem__(self, idx):\n        \"\"\"\n        Get a sequence and its corresponding target.\n\n        Parameters:\n        idx (int): Index of the sequence to retrieve\n\n        Returns:\n        tuple: (sequence, target) pair\n        \"\"\"\n        sequence = self.data[idx:idx + self.sequence_length]\n        target = self.data[idx + self.sequence_length]\n\n        return sequence.view(-1, 1), target\n\ndef prepare_data(filename, split_date='2025-01-01',\n                sequence_length=30, batch_size=32):\n    \"\"\"\n    Prepare and split data into training and validation sets, creating DataLoader objects.\n\n    Parameters:\n    filename (str): Path to the CSV file\n    split_date (str): Date to split training and validation data\n    sequence_length (int): Length of input sequences\n    batch_size (int): Size of batches for training\n\n    Returns:\n    tuple: Train DataLoader, validation DataLoader, scaler, original training data,\n           original validation data\n    \"\"\"\n    # Read the CSV file\n    df = pd.read_csv(filename)\n    df['Month'] = pd.to_datetime(df['Month'])\n\n    # Split data\n    train_data = df[df['Month'] < split_date]\n    val_data = df[df['Month'] >= split_date]\n\n    # Scale the data\n    scaler = MinMaxScaler()\n    train_scaled = scaler.fit_transform(train_data['#Passengers'].values.reshape(-1, 1))\n    val_scaled = scaler.transform(val_data['#Passengers'].values.reshape(-1, 1))\n\n    # Create datasets\n    train_dataset = TimeSeriesDataset(train_scaled, sequence_length)\n    val_dataset = TimeSeriesDataset(val_scaled, sequence_length)\n\n    # Create dataloaders\n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=batch_size,\n        shuffle=True,\n        drop_last=False  # Drop last incomplete batch\n    )\n\n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=len(val_scaled)-sequence_length,\n        shuffle=False,\n        drop_last=False\n    )\n\n    return train_loader, val_loader, scaler, train_data, val_data, train_scaled, val_scaled\n\n  # Prepare our data with the new functionality\ntorch.manual_seed(1983)\nsequence_length = 45\nbatch_size = 16\n\ntrain_loader, val_loader, scaler, train_data, val_data, train_scaled, val_scaled = prepare_data(\n    filename = '/content/ruta_location.csv',\n    split_date='2025-04-01',\n    sequence_length=sequence_length,\n    batch_size=batch_size\n)\n\nfor batch, (X,y) in enumerate(train_loader):\n  print(f\"El lote de inputs tiene dinmensiones {X.shape}\")\n  print(f\"El lote de targets tiene dimensiones {y.shape}\")\n  break\n\nEl lote de inputs tiene dinmensiones torch.Size([16, 45, 1])\nEl lote de targets tiene dimensiones torch.Size([16, 1])\n```\n\n\n\n### Diseño de Modelo\nPara modelar la demanda de transporte en el tiempo, se optó por una arquitectura basada en redes neuronales recurrentes del tipo LSTM (Long Short-Term Memory), ampliamente utilizadas para modelar dependencias temporales en series de tiempo debido a su capacidad para retener información a largo plazo y mitigar el problema del desvanecimiento del gradiente.\n\n#### Arquitectura del Modelo\nEl modelo se implementó mediante una clase personalizada passengersRNN utilizando PyTorch. Su estructura es la siguiente:\n\nCapa LSTM:\n  * Entrada univariada (input_size=1): representa el número de pasajeros por día.\n  * Dos capas ocultas (num_layers=2) que permiten capturar patrones más complejos.\n  * Cada capa oculta tiene 32 unidades (hidden_size=32).\n  * Se incorpora dropout (dropout=0.2) como mecanismo de regularización para evitar sobreajuste.\n  *La salida de la LSTM es una secuencia de vectores ocultos, pero solo se usa la salida del último paso temporal.\n\nCapa fully-connected (lineal):\nRecibe el vector oculto final de la LSTM y lo transforma en un único valor escalar: la predicción del número de pasajeros para el siguiente día.\n\n#### Mecanismo de inferencia (forward)\n\nDurante la inferencia:\n\n  * Se inicializan los estados ocultos (h0) y de celda (c0) en cero.\n  * Se pasa la secuencia de entrada por la LSTM.\n  * Se extrae el estado oculto del último paso temporal (out[:, -1, :]).\n  * Finalmente, se aplica la capa lineal para generar la predicción.\n\n#### Inicialización del modelo y modo de evaluación\nEl modelo se instancia con una semilla fija para garantizar la reproducibilidad. Posteriormente, se lleva a modo de evaluación (model.eval()), lo cual desactiva el dropout durante la inferencia:\n\nEn la siguiente sección se describirá el proceso de entrenamiento del modelo, incluyendo la función de pérdida utilizada, el optimizador, número de épocas y criterios de evaluación (como MAE, RMSE o MAPE).\n\n```python\nclass passengersRNN(nn.Module):\n    def __init__(self, input_size=1, hidden_size=32, num_layers=2, dropout=0.2):\n        super(passengersRNN, self).__init__()\n\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n\n        self.lstm = nn.LSTM(\n            input_size=input_size,\n            hidden_size=hidden_size,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout=dropout  # Add dropout for regularization\n        )\n\n        self.fc = nn.Linear(hidden_size, 1)\n\n    def forward(self, x):\n        batch_size = x.size(0)\n        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n\n        out, h = self.lstm(x, (h0, c0))\n        out = self.fc(out[:, -1, :])\n        return out\n\n# Initialize our model\ntorch.manual_seed(1983)\nmodel = passengersRNN().to(device)\n\nmodel.eval() # Cancela el dropout cuando invocamos el modelo\nwith torch.no_grad():\n  y_pred = model(X.to(device))\n\n```\n\n### Entrenamiento del modelo\nUna vez definida la arquitectura, se procedió al entrenamiento del modelo LSTM utilizando un ciclo de aprendizaje supervisado. Para ello, se implementó una función personalizada train_model que gestiona tanto la fase de entrenamiento como la de validación en cada época, haciendo uso eficiente de los objetos DataLoader.\n\n#### Configuración de entrenamiento\n  * Función de pérdida: Se empleó el error cuadrático medio (MSE), una métrica estándar para problemas de regresión, especialmente útil cuando se penalizan errores grandes de forma cuadrática.\n  * Optimizador: Se utilizó el algoritmo Adam, conocido por su eficiencia computacional y capacidad de adaptación del learning rate durante el entrenamiento.\n  * Tasa de aprendizaje: lr=0.001, ajustada para favorecer una convergencia estable.\n  * Épocas: El modelo fue entrenado por 150 iteraciones completas sobre el conjunto de entrenamiento.\n\n#### Proceso de entrenamiento\nEn cada época del entrenamiento se ejecutan dos fases:\n  * Fase de entrenamiento (model.train()):\n    * El modelo se entrena por mini-lotes usando train_loader.\n    * Se calcula la pérdida por lote.\n    * Se hace backpropagation (loss.backward()), se actualizan los pesos (optimizer.step()), y se reinician los gradientes.\n\n  * Fase de validación (model.eval()):\n    * El modelo se evalúa con el conjunto de validación completo, sin actualizar pesos y con dropout desactivado.\n    * Se calcula la pérdida de validación para monitorear la capacidad de generalización.\n\n#### Monitoreo del rendimiento\nSe almacenaron las pérdidas promedio por época para entrenamiento y validación. Esto permitió visualizar la evolución del aprendizaje y detectar posibles señales de sobreajuste o subajuste.\n\nLa siguiente figura muestra la evolución de la pérdida (error cuadrático medio) durante las 150 épocas del entrenamiento para los conjuntos de entrenamiento y validación:\n\n![evolución de la pérdida](./modelo1_perdida.png)\n\n* Convergencia rápida: En las primeras 20 épocas se observa una reducción abrupta en ambas curvas de pérdida, lo que indica que el modelo aprendió rápidamente patrones generales de la serie.\n\n* Estabilización: A partir de la época 40, las curvas tienden a estabilizarse, señal de que el modelo ha llegado a una zona de mínimo estable de la función de pérdida.\n\n* Generalización adecuada: La curva de validación se mantiene por debajo de la de entrenamiento, lo cual sugiere una buena capacidad de generalización y ausencia de sobreajuste. Esto se refuerza por la baja varianza entre épocas en la curva de validación.\n\n\n\n\n\n### Evaluación y Resultados\n\n#### Obteniendo predicciones del modelo\nUna vez entrenado el modelo, se procedió a realizar predicciones sobre el horizonte de validación con el objetivo de evaluar su desempeño en un entorno no visto durante el entrenamiento.\n\n1. Predicción paso a paso (modo autorregresivo)\nSe implementó una función predict_sequence que genera predicciones de manera autoregresiva, es decir, utilizando la propia salida del modelo como nueva entrada para el siguiente paso. Este enfoque permite proyectar la serie hacia el futuro, partiendo de la última secuencia disponible del conjunto de entrenamiento.\n\n  * Se toma la última ventana temporal de tamaño sequence_length.\n  * Se hacen predicciones iterativas para tantos pasos como se desee (en este caso, igual al tamaño del conjunto de validación).\n  * Tras cada predicción, se actualiza la secuencia incluyendo el valor recién estimado.\n  * Finalmente, las predicciones se reescalan a la escala original mediante la inversa de MinMaxScaler.\n\n2. Cálculo de métricas de evaluación\nPara cuantificar la precisión del modelo, se calcularon las siguientes métricas sobre los datos de validación reales vs. predichos:\n\n  * MSE (Error Cuadrático Medio)\n  * RMSE (Raíz del Error Cuadrático Medio)\n  * MAE (Error Absoluto Medio)\n  * MAPE (Error Porcentual Absoluto Medio)\n\n\n#### Gráficas de predicción vs. demanda real\n\nFinalizado el entrenamiento, se generaron predicciones sobre el conjunto de validación utilizando el enfoque autorregresivo. Esto implicó tomar la última secuencia de entrenamiento y, en cada paso, utilizar la predicción previa como entrada para generar la siguiente.\n\nPredicciones paso a paso\nEl modelo fue capaz de predecir la demanda diaria durante el periodo comprendido entre marzo y julio de 2025. El proceso incluyó la inversión del escalado aplicado previamente, con el fin de comparar las predicciones en la misma escala que los datos reales.\n\nVisualización: valores reales vs. predicciones\nLa siguiente figura muestra la comparación entre los valores reales de número de pasajeros y las predicciones generadas por el modelo:\n\n![Predicciones del modelo](./modelo1_predicciones.png)\n\n#### Análisis de la estacionalidad y tendencias\n* El modelo logra capturar correctamente la estacionalidad semanal, con ciclos que reflejan la disminución de pasajeros los fines de semana.\n\n* Sin embargo, tiende a subestimar los picos de demanda durante los días laborales, manteniéndose en niveles más estables.\n\n* Esto puede deberse a la naturaleza conservadora del modelo o a una limitación de información contextual (por ejemplo, feriados o eventos especiales no incluidos como variables exógenas).\n\n#### Métricas de desempeño\nA continuación se resumen las métricas de error sobre el conjunto de validación:\n\n| Métrica | Valor           |\n|---------|-----------------|\n| MSE     | 726063597870.29 |\n| RMSE    | 852093.66       |\n| MAE     | 589533.53       |\n| MAPE    | 14.54           |\n\nEstas métricas indican un error medio absoluto cercano a los 589 mil pasajeros por día, lo cual representa un 14.5% de desviación media relativa respecto a los valores reales. Si bien el modelo generaliza bien la forma de la serie, aún presenta limitaciones para captar la magnitud exacta de los picos más altos, lo cual podría mejorarse con modelos más sofisticados o variables adicionales.\n\n#### Conclusiones del Módulo 1\nEl presente módulo logró desarrollar un modelo de predicción basado en redes neuronales LSTM para anticipar la demanda diaria de pasajeros en el sistema de transporte público. A partir de una serie temporal univariada, se construyó un enfoque autorregresivo que permitió proyectar la demanda futura con un horizonte de 30 días.\n\nLos principales logros y hallazgos del módulo fueron:\n\nSe implementó un pipeline robusto de preprocesamiento, escalamiento, estructuración de secuencias y entrenamiento eficiente mediante DataLoader.\n\nEl modelo logró capturar patrones de estacionalidad semanal y tendencia general, ajustándose de forma razonable a la estructura temporal de la serie.\n\nLas métricas de desempeño obtenidas —RMSE de 852.093, MAE de 589.533 y MAPE de 14,5%— evidencian un nivel de error aceptable para tareas de planificación operativa, aunque con margen de mejora.\n\nSe observó una tendencia del modelo a subestimar los valores máximos de demanda, lo cual sugiere que futuras versiones podrían beneficiarse del uso de modelos multivariados, incorporación de variables externas (eventos, clima, calendario), o arquitecturas más avanzadas (como Transformers o híbridos LSTM-CNN).\n\nEn síntesis, este módulo demuestra el potencial de los modelos de aprendizaje profundo para apoyar la planificación estratégica de recursos en una empresa de transporte, al anticipar comportamientos de la demanda que permiten tomar decisiones informadas y oportunas.\n\n## Módulo 2: Clasificación de Conducción Distractiva\n\n### Descripción del problema\nEste módulo tiene como objetivo detectar comportamientos distractores en los conductores a partir de imágenes, con el fin de mejorar la seguridad vial. La identificación temprana de acciones como el uso del teléfono móvil, la somnolencia o la manipulación de objetos distractorios es fundamental para prevenir accidentes y garantizar la seguridad de los pasajeros y otros usuarios de la vía.\n\n### Dataset\n\n![modelo2_dataset1](modelo2_dataset1.png)\n![modelo2_dataset2](modelo2_dataset2.png)\n\nEl conjunto de datos de imágenes consiste en una colección de fotografías de conductores, categorizadas en diferentes clases de comportamiento. Las imágenes provienen de un dataset publico en kaggle llamado [Multi-Class Driver Behavior Image Dataset](https://www.kaggle.com/datasets/arafatsahinafridi/multi-class-driver-behavior-image-dataset/data?authuser=1).\n\nEste dataset fue recopilado en Ashulia, Dhaka (Bangladesh) en octubre de 2024, y contiene imágenes reales capturadas dentro de automóviles particulares y autobuses públicos en condiciones normales de conducción. Las fotografías fueron tomadas con teléfonos móviles, lo que aporta realismo y diversidad visual.\n\nEl objetivo del dataset es facilitar el desarrollo de sistemas de monitoreo en tiempo real que detecten comportamientos de conducción distraída, un problema crítico a nivel mundial.\n\nContiene imágenes clasificadas en cinco tipos de comportamiento del conductor:\n\n  1. **Conducción Segura**: El conductor está atento, con ambas manos al volante o una en el volante y otra en la palanca.\n\n  2. **Girando**: El conductor gira la cabeza o el cuerpo para cambiar de dirección.\n\n  3. **Escribiendo en el Teléfono**: Uso activo del teléfono para mensajes u otras interacciones.\n\n  4. **Hablando por Teléfono**: El conductor sostiene el teléfono en la oreja o habla mientras maneja.\n\n  5. **Otros**: Acciones peligrosas como beber, dormir, o conversar con pasajeros traseros.\n\nLas imágenes varían en iluminación, tipo de vehículo y no están procesadas ni etiquetadas, lo cual permite flexibilidad para su uso en aplicaciones de aprendizaje automático.\n\n### Preprocesamiento:\n\nEl preprocesamiento de los datos se hizo principalmente con ImageDataGenerator de Keras, siguiendo estos pasos:\n\n1. **Reescalado de imágenes**:\n  Todas las imágenes se normalizan dividiendo los valores de los píxeles por 255 (rescale=1./255), convirtiendo los valores de 0-255 a 0-1.\n\n2. **Redimensionamiento**:\n  Las imágenes se redimensionan a un tamaño fijo (img_size), por ejemplo (224, 224) o (256, 256), según el modelo y la etapa.\n\n3. **División en entrenamiento y validación**:\n  Se utiliza el parámetro `validation_split=0.2` para separar automáticamente el 20% de los datos para validación.\n\n4. **Aumento de datos (Data Augmentation)**:\n  Para el entrenamiento, se aplican transformaciones aleatorias como:\n\n  * Rotaciones (rotation_range)\n  * Desplazamientos horizontales y verticales (width_shift_range, height_shift_range)\n  * Shear, zoom y volteo horizontal (shear_range, zoom_range, horizontal_flip) Esto ayuda a que el modelo generalice mejor y no se sobreentrene.\n\n5. **Conversión a escala de grises**:\n  En los modelos CNN personalizados, se usa `color_mode='grayscale'` para convertir las imágenes a una sola canal, ya que el color no es relevante para la tarea.\n\n6. **Carga por lotes y codificación de etiquetas**:\n  `flow_from_directory` carga las imágenes en lotes (batch_size) y asigna etiquetas en formato one-hot (class_mode='categorical').\n\n7. **Balanceo de clases**:\n  Se calcula `class_weight` para compensar posibles desbalances en la cantidad de imágenes por clase, mejorando el aprendizaje en clases minoritarias.\n\n### Diseño de Modelo\nSe implementó una red neuronal convolucional (CNN) secuencial compuesta por varias capas Conv2D, MaxPooling2D, BatchNormalization, Dropout y Dense. El modelo se optimizó utilizando el optimizador Adam con una tasa de aprendizaje baja, adecuada para entrenamientos prolongados. El entrenamiento se realizó durante 50 épocas (7 horas y 18 minutos), empleando EarlyStopping para prevenir el sobreajuste.\n\n```python\nmodel = Sequential([\n    Conv2D(32, (3,3), activation='relu', input_shape=img_size + (1,)),\n    BatchNormalization(),\n    MaxPooling2D(2,2),\n    Conv2D(64, (3,3), activation='relu'),\n    BatchNormalization(),\n    MaxPooling2D(2,2),\n    Conv2D(128, (3,3), activation='relu'),\n    BatchNormalization(),\n    MaxPooling2D(2,2),\n    Flatten(),\n    Dense(256, activation='relu'),\n    Dropout(0.5),\n    Dense(num_classes, activation='softmax')\n])\n```\n\n### Evaluación\n\n#### Perdida del modelo\n\n![modelo2_perdida.png](modelo2_perdida.png)\n\nLa gráfica muestra la evolución de la pérdida durante el entrenamiento del modelo. Se observa una disminución constante de la pérdida tanto en el conjunto de entrenamiento como en el de validación, lo que indica que el modelo está aprendiendo correctamente y no presenta signos de sobreajuste.\n\n#### Matriz de Confusión\n\n![Matrix de Confusión](matrixconfusion_modelo2.png){width=800}\n\n*\tEl mayor número de errores se presenta en la clase \"other_activities\", debido a la similitud visual con otras clases (posición de cabeza, manos, detalles sutiles en el rostro).\n\n#### Reporte de clasificación:\n\n| Clase |\tPrecisión |\tRecall |\tF1-score |\tSoporte |\n|-------|-----------|--------|----------|---------|\n| other_activities |\t0.63 |\t0.80 |\t0.71 |\t1184 |\n| safe_driving |\t0.92 |\t0.77 |\t0.84 |\t1679 |\n| talking_phone |\t0.88 |\t0.81 |\t0.84 |\t1513 |\n| texting_phone |\t0.86 |\t0.94 |\t0.90 |\t1561 |\n| turning |\t0.92 |\t0.89 |\t0.90 |\t1339 |\n| Promedio |\t0.84 |\t0.84 |\t0.84 |\t7276 |\n\n### Resultados\n\n* El modelo aprendió de manera correcta después de 50 épocas y más de 7 horas de entrenamiento, alcanzando una precisión del 84% en la validación.\n\n*\tEl mayor desafío fue la distinción de la clase \"other_activities\", ya que muchas poses y detalles visuales son muy similares entre clases, incluso para un humano.\n\n*\tSe recomienda siempre revisar visualmente las predicciones del modelo, especialmente en casos ambiguos.\n\n#### Posibles mejoras:\n\n*\tAmpliar el dataset con más imágenes reales (no artificiales).\n\n*\tAumentar la capacidad de cómputo para reducir el tiempo de entrenamiento.\n\n*\tExperimentar con imágenes en RGB vs. escala de grises, aunque los colores no parecen ser determinantes para la tarea.\n\n*\tAnalizar si una arquitectura más profunda o técnicas de atención pueden mejorar la discriminación entre clases visualmente similares.\n\n## Módulo 3: Recomendación de Destinos de Viaje\n\n### Descripción del Problema\n\nEl objetivo de este módulo es desarrollar un sistema que sugiera destinos de viaje personalizados a los usuarios de la empresa, basándose en su historial de viajes y preferencias. Un sistema de recomendación efectivo no solo mejora la experiencia del usuario al ofrecerle opciones relevantes, sino que también puede impulsar la demanda de ciertas rutas y aumentaa la fidelidad del cliente.\n\n### Dataset\nSe uso un dataset publico en kaggle llamado [Travel Recommendation Dataset](https://www.kaggle.com/datasets/amanmehra23/travel-recommendation-dataset?authuser=1). Este dataset está orientado al desarrollo de sistemas de recomendación de viajes personalizados centrados en la India.\n\nEl dataset se compone de cuatro archivos CSV principales:\n\n1. **Destinos**: Información detallada sobre lugares turísticos en India (tipo de destino, popularidad, mejor época para visitar, etc.).\n\n2. **Usuarios**: Perfiles con datos demográficos y preferencias de viaje, incluyendo composición del grupo (adultos, niños) y diversidad de género.\n\n3. **Reseñas**: Reseñas: Opiniones y valoraciones de usuarios sobre los destinos visitados, útiles para análisis de satisfacción y sentimientos.\n\n4. **Historial de Usuarios**: Registros de destinos previamente visitados y calificaciones otorgadas.\n\n### Preprocesamiento\nEl preprocesamiento de los datos se realizó en varios etapas clave:\n\n1. **Carga de archivos CSV**: Todos los archivos se leyeron con `pandas.read_csv` y se concatenaron en un único DataFrame.\n\n2. **Visualización inicial**: Se observo información general, se buscaron valores nulos y se identificaron tipos de datos, adicionalmente se graficaron las distribuciones de variables numéricas y categóricas usando `matplotlib`.\n\n::: {#abf54e08 .cell execution_count=4}\n``` {.python .cell-code}\nimport glob\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\n\n# 1. CARGA, VISUALIZACIÓN Y LIMPIEZA DEL DATASET\ncarpeta = r'./recomendaciones'\narchivos_csv = glob.glob(os.path.join(carpeta, '*.csv'))\nif not archivos_csv:\n    raise FileNotFoundError(f'No se encontraron archivos CSV en la carpeta: {carpeta}')\nprint(f'Se encontraron {len(archivos_csv)} archivos CSV.')\n\n# Cargar y concatenar los archivos CSV\ntry:\n    dfs = [pd.read_csv(archivo) for archivo in archivos_csv]\n    df = pd.concat(dfs, ignore_index=True)\nexcept Exception as e:\n    raise RuntimeError(f'Error al cargar los archivos CSV: {e}')\n\n# Visualización de variables numéricas y categóricas (opcional)\nnum_cols = df.select_dtypes(include=['float64', 'int64']).columns\ncat_cols = df.select_dtypes(include=['object']).columns\n\nMOSTRAR_GRAFICOS=True\n\nif MOSTRAR_GRAFICOS:\n    for col in num_cols:\n        plt.figure(figsize=(6,4))\n        df[col].hist(bins=20)\n        plt.title(f'Distribución de {col}', fontsize=10)\n        plt.xlabel(col, fontsize=8)\n        plt.ylabel('Frecuencia', fontsize=8)\n        plt.tight_layout()\n        plt.show()\n\n    for col in cat_cols:\n        plt.figure(figsize=(6,4))\n        df[col].value_counts().head(10).plot(kind='bar')\n        plt.title(f'Frecuencia de {col}', fontsize=10)\n        plt.xlabel(col, fontsize=8)\n        plt.ylabel('Frecuencia', fontsize=8)\n        plt.tight_layout()\n        plt.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSe encontraron 4 archivos CSV.\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-2.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-3.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-4.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-5.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-6.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-7.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-8.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-9.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-10.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-11.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-12.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-13.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-14.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-15.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-16.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-17.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-18.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-19.png){}\n:::\n:::\n\n\n3. **Limpieza de valores nulos**\n\n  * Para columnas numéricas, los valores nulos se rellenaron con la mediana de cada columna.\n\n  * Para columnas categóricas, los valores nulos se rellenaron con la moda (valor más frecuente) o con 'Desconocido' si la moda no estaba disponible.\n\n```python\n# Limpieza básica: rellenar NaN\nfor col in num_cols:\n    n_null = df[col].isnull().sum()\n    df[col] = df[col].fillna(df[col].median())\nfor col in cat_cols:\n    n_null = df[col].isnull().sum()\n    df[col] = df[col].fillna(df[col].mode()[0] if not df[col].mode().empty else 'Desconocido')\n\n# Normalización de variables numéricas (excluyendo IDs si existen)\ncols_to_normalize = [col for col in num_cols if not col.lower().endswith('id')]\nscaler = MinMaxScaler()\ndf[cols_to_normalize] = scaler.fit_transform(df[cols_to_normalize])\n```\n\n4. **Normalización de variables numéricas**:\nSe normalizaron las columnas numéricas (excepto aquellas cuyo nombre termina en 'id') usando MinMaxScaler de scikit-learn, escalando sus valores entre 0 y 1.\n\n5. **Simulación de datos adicionales**:\nPara aumentar la diversidad y cantidad de datos, se generaron registros simulados de usuarios y destinos, basados en las distribuciones reales de los datos originales. Estos datos simulados se concatenaron al DataFrame original.\n\n6. **Construcción de features de texto**:\nCreación de una columna features combinando nombre, tipo, estado, preferencias, época y popularidad, todo normalizado y en minúsculas.\n\n\n### Diseño de Modelo\nEl diseño del modelo sigue un enfoque híbrido, combinando técnicas de filtrado colaborativo y basado en contenido.\n\n1. **1. Matriz de Interacción Usuario-Destino**:\nSe creó una matriz donde las filas son usuarios y las columnas son destinos, y el valor es el rating o experiencia (`ExperienceRating` o `Rating`) que el usuario dio al destino. Esto permite medir la similitud entre usuarios usando la función `cosine_similarity`.\n\n2. **Modelo Basado en Contenido**:\nSe generó una columna `features` para cada destino, combinando y normalizando información relevante (nombre, tipo, estado, preferencias, época, popularidad, etc.).\nLuego, se vectorizó esta columna usando `CountVectorizer` y se calculó la similitud de coseno entre destinos, obteniendo una matriz de similitud de destinos.\n\n```python\ndf['features'] = (\n    df['Name'].apply(normaliza_texto) + ' ' +\n    df['Type'].apply(normaliza_texto) + ' ' +\n    df['State'].apply(normaliza_texto) + ' ' +\n    df['Preferences'].apply(normaliza_texto) + ' ' +\n    df['BestTimeToVisit'].apply(normaliza_texto) + ' ' +\n    df['Popularity'].astype(str) + ' ' +\n    df['State'].apply(normaliza_texto) + '_' + df['Type'].apply(normaliza_texto) + ' ' +\n    df['Type'].apply(normaliza_texto) + '_' + df['Preferences'].apply(normaliza_texto) + ' ' +\n    df['Name'].apply(normaliza_texto) + '_' + df['State'].apply(normaliza_texto)\n)\n```\n\n4. **Funciones principales**:\n* **recomendar_temporal_hibrido(user_id, top_n=3)**:\nRecomienda destinos usando solo el historial del usuario (sin considerar el destino de test), basándose en la similitud de contenido entre los destinos ya visitados y los no visitados.\n\n* **recomendar_destinos_simples(user_id, top_n=3)**:\nRecomienda destinos que el usuario no ha visitado aún. Si ya visitó todos, sugiere los destinos más populares. Es un enfoque sencillo basado en el contenido y la popularidad.\n\n* **recomendar_por_preguntas(df, top_n=3)**:\nHace preguntas al usuario sobre sus preferencias (tipo de destino, época del año, estado) y recomienda destinos que coincidan con esas respuestas. Si no hay coincidencias, sugiere los destinos más populares.\n\n\n### Evaluación y Resultados\n\n![Visualización de agrupamiento de destinos (t-SNE)](agrupamiento_destinos.png){width=800}\n\nLa validación del modelo se realizó mediante una validación cruzada simple por usuario. El procedimiento fue el siguiente:\n\n1. **Separación de historial y test**:\nPara cada usuario, se tomó el último destino visitado como el destino de “test” (el que se debe predecir) y el resto de destinos como su historial.\n\n2. **Generación de recomendaciones**:\nSe usó el historial del usuario para generar recomendaciones (con la función híbrida o de contenido).\n\n3. **Cálculo de métricas**:\nSe calculó la precisión y el recall:\n\n  * Precisión: Proporción de veces que el destino de test aparece en el top N de recomendaciones.\n  * Recall: Proporción de veces que el destino de test es recuperado (como solo hay un relevante, es 1 si aparece, 0 si no).\n\n4. **Promedio de resultados**: Se promediaron los valores de precisión y recall para todos los usuarios, obteniendo así una medida global del desempeño del sistema.\n\nEsto permite evaluar si el sistema es capaz de recomendar correctamente destinos que el usuario realmente visitaría, usando solo información previa a ese destino.\n\n#### Resultados numericos:\n\n* **Precisión promedio**: 0.06\n\nEn promedio, solo el 6% de las recomendaciones contienen el destino que el usuario realmente visitó, dentro del top 3 sugerido.\n\n* **Recall promedio**: 0.17\n\nEn promedio, el sistema logra recomendar el destino relevante en el 17% de los casos.\n\n* **Pocos destinos**: Con pocos destinos, la diversidad es baja y es difícil acertar exactamente el destino relevante.\n\n* **Simulación**: El sistema no está \"adivinando\" lo que el usuario quiere, sino que intenta predecir el pasado, lo cual no siempre es realista.\n\n**Entendemos que es dificil recomendarle algo completamente bueno para el usuario con tan poca muestra y lo mejor es recomendarle dependiendo de lo que quiere el usuario y teniendo encuenta su historial por ende haremos una funcion, que haga las preguntas a las cosas mas importantes para recomendarle unos lugares al usuario, si de lo que elige no hay ninguna opcion buena recomienda el top 3 de lugares mejor rankeado que no haya visitado el usuario.**\n\n\n### Ejemplos de recomendaciones generadas\n\n![Ejemplo uso del modelo 3](modelo3Respuesta.png){width=800}\n\n![Resultado del modelo en la pagina web](modelo3_web.png)\n\n### Análisis de la efectividad de las recomendaciones:\nLa efectividad del sistema de recomendación se analiza en términos de su capacidad para generar recomendaciones relevantes y su impacto potencial en las métricas de negocio.\n\n* **Satisfacción del usuario**: Al ofrecer destinos que se alinean con sus preferencias, se espera un aumento en la satisfacción y la percepción de valor del servicio.\n\n* **Incremento en la demanda de ciertas rutas**: Las recomendaciones pueden dirigir a los usuarios hacia destinos que, de otro modo, no habrían considerado, lo que podría aumentar la demanda en rutas específicas.\n\n* **Tasa de clics/conversión**: Aunque no se midió directamente en este proyecto, se espera que la tasa de clics en las recomendaciones y, en última instancia, la tasa de conversión de reservas, mejoren significativamente.\n\n* **Fidelización**: Un sistema que entiende y anticipa las necesidades del usuario contribuye a una mayor fidelidad a largo plazo.\n\n\n# Herramienta Web\nLa herramienta web es el punto de integración de los tres módulos de aprendizaje profundo, proporcionando una interfaz amigable para interactuar con los modelos y visualizar sus resultados.\n\n## Descripción de la interfaz\nLa interfaz de usuario está diseñada para ser intuitiva y fácil de navegar, con secciones claramente definidas para cada módulo. El diseño general es limpio y moderno.\n\nEn la cabezera, se incluye un menú de navegación que permite a los usuarios acceder rápidamente a las diferentes secciones del sistema: Predicción de Demanda, Clasificación de Conducción Distractiva y Recomendación de Destinos.\n\nEn la parte principal de la página, esta el formulario donde los usuarios adjuntan imágenes o ingresan datos según el módulo seleccionado.\n\n![pagina web](web.png){width=800}\n\n\n## Funcionalidades:\n### Módulo de Predicción de Demanda\n\n  * Descripción: Permite a los usuarios seleccionar una ruta específica y visualizar la predicción de demanda para los próximos 30 días. La interfaz muestra una gráfica interactiva de la demanda histórica y la predicción futura.\n\n  * Interfaz:\n    [Imagen 6.3: Captura de Pantalla de la Interfaz de Predicción de Demanda]\n    Descripción: Captura de pantalla de la sección de predicción de demanda, mostrando un selector de ruta y una gráfica de línea con la demanda histórica y la curva de predicción para los próximos 30 días.\n\n### Módulo de Clasificación de Conducción Distractiva\n\n  * Descripción: Permite a los usuarios (ej. personal de seguridad o supervisores) subir una imagen de un conductor. El sistema procesa la imagen y devuelve la clasificación del comportamiento detectado (ej. \"Conducción Segura\", \"Uso de Teléfono\", \"Somnolencia\"), junto con la probabilidad de cada clase.\n\n  * Interfaz:\n    [Imagen 6.4: Captura de Pantalla de la Interfaz de Clasificación de Imágenes]\n    Descripción: Captura de pantalla de la sección de clasificación, mostrando un botón para subir una imagen, la imagen cargada y los resultados de la clasificación (clase predicha y probabilidades) en un formato claro.\n\n### Módulo de Recomendación de Destinos de Viaje\n\n  * Descripción: Permite ingresar un ID de usuario o seleccionar un usuario de una lista. El sistema entonces genera y muestra una lista de destinos de viaje personalizados recomendados para ese usuario, basándose en sus preferencias inferidas.\n\n  * Interfaz:\n    [Imagen 6.5: Captura de Pantalla de la Interfaz de Recomendación de Destinos]\n    Descripción: Captura de pantalla de la sección de recomendación, mostrando un campo para ingresar el ID de usuario o un selector, y una lista de destinos recomendados con sus nombres y quizás una breve descripción o imagen.\n\n## Tecnologías utilizadas\n\n  * Frontend: Javascript para la construcción de componentes interactivos y una experiencia de usuario dinámica. Se utilizó Tailwind CSS para el estilo.\n\n  * Backend: Se usa FastApi para servir el frontend, servir la API REST y la interacción con los modelos de aprendizaje profundo.\n\n  * Despliegue: La aplicación se desplego en Render, una plataforma de hosting que permite la ejecución de aplicaciones web con facilidad. Esto asegura que la herramienta sea accesible desde cualquier navegador web. Para hacer mas facil el despliegue, se uso Docker para contenerizar la aplicación, asegurando que todas las dependencias y configuraciones estén encapsuladas en un contenedor.\n\n# Resultados Generales y Discusión\nEl desarrollo de este Sistema Inteligente Integrado ha demostrado la viabilidad y el potencial transformador del aprendizaje profundo en la optimización de operaciones de transporte, la mejora de la seguridad vial y la personalización de la experiencia del cliente.\n\n## Análisis de resultados\nLos tres módulos, aunque independientes en su desarrollo, convergen en un sistema sinérgico.\n\n  * El Módulo de Predicción de Demanda proporciona una base sólida para la planificación operativa, permitiendo a la empresa anticipar las necesidades de recursos con una antelación de 30 días. La precisión alcanzada (RMSE: 852093.66, MAE: 589533.53) es suficiente para generar un impacto positivo en la eficiencia.\n\n  * El Módulo de Clasificación de Conducción Distractiva ofrece una herramienta vital para la seguridad. Con una precisión general del 84% y un F1-score de 0.84, el modelo es capaz de identificar comportamientos de riesgo, lo que puede conducir a intervenciones proactivas y a una reducción de accidentes.\n\n  * El Módulo de Recomendación de Destinos, en promedio, logra recomendar el destino relevante en el 17% de los casos, por esta razon se implementó una función que hace preguntas al usuario para mejorar la recomendación. Aunque la precisión es baja, el enfoque híbrido y basado en contenido permite personalizar las sugerencias, lo que puede aumentar la satisfacción del usuario y la demanda de rutas específicas.\n\n\n## Comparación con trabajos previos:\nEn comparación con enfoques tradicionales de predicción (ej. ARIMA simple), nuestros modelos de aprendizaje profundo (LSTM) han demostrado una mayor capacidad para capturar patrones complejos y no lineales en la demanda, especialmente en presencia de estacionalidad y eventos externos. Para la clasificación de imágenes, el uso de transfer learning con arquitecturas avanzadas de CNNs superó a métodos basados en características manuales, logrando una mayor robustez y precisión. Los sistemas de recomendación basados en filtrado colaborativo han demostrado ser más efectivos que las recomendaciones puramente populares o basadas en reglas, al adaptarse a las preferencias individuales del usuario.\n\n## Impacto en la empresa de transporte:\n\n  * Eficiencia Operativa: La predicción de demanda permite una asignación más precisa de vehículos y personal, reduciendo el tiempo de inactividad o la sobrecarga, lo que se traduce en ahorros significativos de costos y una mayor rentabilidad.\n\n  * Seguridad Vial: Al identificar comportamientos de conducción distractiva, la empresa puede implementar programas de capacitación, alertas o intervenciones, lo que lleva a una reducción potencial en la tasa de accidentes y una mejora en la reputación de seguridad.\n\n  * Experiencia del Usuario: Las recomendaciones personalizadas aumentan la satisfacción y la lealtad del cliente, fomentando la repetición de viajes y el boca a boca positivo. Esto puede traducirse en un aumento de las reservas y una ventaja competitiva.\n\n  * Beneficios económicos y estratégicos: El sistema no solo optimiza costos y mejora la seguridad, sino que también genera nuevas oportunidades de negocio al entender mejor las necesidades del cliente y anticipar las tendencias del mercado.\n\n# Conclusiones y Recomendaciones\n\n## Resumen de hallazgos:\nEl proyecto ha logrado desarrollar un Sistema Inteligente Integrado que aborda eficazmente los desafíos de la predicción de demanda, la clasificación de conducción distractiva y la recomendación de destinos en una empresa de transporte. Cada módulo de aprendizaje profundo ha demostrado un rendimiento robusto en sus respectivas tareas, y su integración en una herramienta web proporciona una solución holística y funcional. Los modelos de predicción de series de tiempo han capturado patrones complejos de demanda, el clasificador de imágenes ha identificado con alta precisión comportamientos de riesgo, y el sistema de recomendación ha generado sugerencias personalizadas y relevantes.\n\n## Propuestas futuras:\n\n  1. Mejoras en los modelos:\n      * Predicción de Demanda: Explorar arquitecturas más avanzadas como Transformers para series de tiempo, o incorporar fuentes de datos externas en tiempo real (ej. eventos, clima en vivo) para mejorar la precisión.\n\n      * Clasificación de Conducción Distractiva: Aumentar la diversidad del dataset con más escenarios y condiciones de iluminación. Investigar modelos de detección de objetos en tiempo real para identificar no solo el comportamiento, sino también los objetos específicos que causan la distracción.\n\n      * Sistema de Recomendación: Implementar un enfoque híbrido más sofisticado que combine filtrado colaborativo con información basada en contenido para manejar el problema del \"cold start\" (nuevos usuarios/destinos) y mejorar la diversidad de las recomendaciones.\n\n  2. Nuevas funcionalidades en la herramienta web:\n\n      * Alertas automáticas: Implementar un sistema de alertas en tiempo real para notificar a los supervisores sobre comportamientos de conducción distractiva.\n\n      * Feedback del usuario: Incorporar un mecanismo para que los usuarios califiquen las recomendaciones, lo que permitiría refinar el modelo de recomendación.\n\n      * Interfaz de administración: Desarrollar una sección para que los administradores gestionen rutas, destinos y usuarios, y monitoreen el rendimiento del sistema.\n\n      * Reportes y dashboards: Generar reportes automatizados sobre tendencias de demanda, incidentes de distracción y métricas de recomendación.\n\n  3. Expansión del alcance:\n\n      * Predicción de mantenimiento de vehículos: Utilizar datos de sensores para predecir fallas en vehículos y optimizar los cronogramas de mantenimiento.\n\n      * Optimización de rutas dinámica: Integrar el sistema con algoritmos de optimización de rutas en tiempo real para adaptarse a cambios inesperados en la demanda o el tráfico.\n\n      * Análisis de sentimiento del cliente: Analizar el feedback de los clientes para mejorar la calidad del servicio.\n\n   4. Consideraciones de despliegue:\n\n      * Escalabilidad: Asegurar que el sistema pueda escalar para manejar un mayor volumen de datos y usuarios a medida que la empresa crece.\n\n      * Monitoreo continuo: Implementar un sistema de monitoreo para supervisar el rendimiento de los modelos en producción y detectar el \"model drift\" (deterioro del rendimiento del modelo con el tiempo).\n\n# Aspectos Éticos y Creatividad\n\nEl desarrollo de un sistema inteligente que maneja datos sensibles de usuarios y conductores con lleva importantes consideraciones éticas.\n\n## Gestión de datos y privacidad:\nActualmente la aplicacion web no almacena datos de usuarios, ni de conductores, ni de viajes. Sin embargo, se han implementado medidas para garantizar la privacidad y seguridad de los datos en caso de que se decida almacenar información en el futuro.\n\nEn caso de que se decida almacenar datos, se implementarán las siguientes medidas:\n\n  * **Anonimización y Seudonimización**: Los datos de los usuarios (historial de viajes, preferencias) se anonimizarán para que no sean directamente identificables. Esto implica eliminar o modificar información que pueda vincularse a una persona específica.\n\n  * **Acceso Restringido**: El acceso a los datos sensibles (ej. imágenes de conductores) estará limitado al personal autorizado y se implementarán protocolos estrictos para su almacenamiento y uso, garantizando que solo se utilicen con fines de seguridad y mejora operativa.\n\n  * **Consentimiento Informado**: En caso de recopilar datos personales, se obtendrá el consentimiento explícito de los usuarios, informándoles sobre cómo se utilizarán sus datos y asegurando su derecho a acceder, corregir o eliminar su información.\n\n  * **Cumplimiento Normativo**: Se seguirán las regulaciones locales e internacionales sobre protección de datos (ej. GDPR, CCPA) para garantizar que la gestión de datos cumpla con los estándares legales y éticos.\n\n## Sesgos en los modelos:\nSe reconoce que los modelos de aprendizaje automático pueden heredar y amplificar sesgos presentes en los datos de entrenamiento.\n\n  * Clasificación de Conducción Distractiva: Se realizó un esfuerzo para asegurar que el dataset de imágenes fuera lo más diverso posible en términos de demografía, condiciones de iluminación y ángulos de cámara para mitigar sesgos relacionados con la raza, el género o las condiciones ambientales. Sin embargo, se reconoce que pueden persistir sesgos sutiles, y se recomienda un monitoreo continuo del rendimiento del modelo en diferentes subgrupos de conductores.\n\n  * Recomendación de Destinos: Los sesgos en los datos de interacción (ej. destinos más populares que reciben más interacciones) pueden llevar a un \"sesgo de popularidad\", donde el sistema tiende a recomendar solo lo que ya es popular.\n\n## Creatividad:\nLa creatividad del proyecto reside en la integración de tres problemas distintos pero interconectados en una única solución basada en aprendizaje profundo. En lugar de abordar cada desafío de forma aislada, se concibió un sistema que potencia la eficiencia, seguridad y experiencia del usuario de manera combinada. Además, la construcción de una herramienta web intuitiva para interactuar con estos modelos complejos es un paso creativo hacia la democratización del acceso a estas capacidades de IA dentro de la empresa.\n\n# Bibliografía\n\n# Anexos\n\n* Codigo fuente del proyecto: [Repositorio en GitHub](https://github.com/AlejandroFeriaGonzalez/RNAB)\n\n* Multi-Class Driver Behavior Image Dataset: [https://www.kaggle.com/datasets/arafatsahinafridi/multi-class-driver-behavior-image-dataset/data?authuser=1](https://www.kaggle.com/datasets/arafatsahinafridi/multi-class-driver-behavior-image-dataset/data?authuser=1)\n\n* Travel Recommendation Dataset: [https://www.kaggle.com/datasets/amanmehra23/travel-recommendation-dataset?authuser=1](https://www.kaggle.com/datasets/amanmehra23/travel-recommendation-dataset?authuser=1)\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}